# Introduction to Warpfusion


In this session, you'll learn how to utilize Warpfusion to process video-to-video generations. Warpfusion utilizes Stable Diffusion to generate user customized images for each frame. We will be able to control and customize Stable Diffusion with several tools including ControlNet.

**Requirements:**
- At least 2GB available on your [Google Drive](drive.google.com)
- [Google Colab Pro or Colab Pro+](https://colab.research.google.com/signup)
- At least 16GB of Nvidia GPU memory
- [Warpfusion script v15](https://www.patreon.com/posts/stable-v0-15-84106537)


1. Open the Notebook in Colab
2. Change the runtime type to `T4` or higher GPU
3. Run parts 1.1-1.3 to install Stable Diffusion dependencies (~ 6 min)
4. Check the box for `Skip Install` in part 1.3
5. Restart the kernel and run all all of the cells from the beginning

<img width="597" alt="image" src="https://github.com/ai-kadhim/Introduction-to-Warpfusion/assets/37101144/2c3aae61-5a3b-4b16-bc52-b75c16c8a403">
